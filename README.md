# 1. 项目介绍
本项目为Kaggle训练项目，项目数据来自欧洲信用卡刷卡记录，项目目的是通过特征训练机器找出欺诈行为，你可以在该[网页](https://www.kaggle.com/mlg-ulb/creditcardfraud)
找到相关数据

# 2. 文件描述
-  models (文件夹)：模型存放
- 信用卡欺诈分析 (ipynb)：研究报告

# 3. 项目研究目录
1. 背景介绍
2. 加载库
3. 数据探访
4. 数据探索分析
5. 模型预测

# 4. 项目小结
本项目使用了真实的信用卡欺诈数据，通过对数据的清洗、可视化、重构特征，了解了数据的基本规律。
在机器模拟预测部分，本项目的模型采用分为了两部分：普通常规分类模型，案例依赖成本敏感分类模型。
在训练数据的选用上，本项目将训练数据分类为：原训练数据，低采样训练数据，过采样训练数据。
对于案例依赖成本敏感分类模型上，为了寻找不同cost下模型的表现区别，将成本矩阵分成了低成本、中成本和高成本矩阵。
在后剪枝上，所有模型又分为了不使用后剪枝，和使用贝叶斯最小风险后剪枝。

训练的结果表示，xgboost模型非常适合本项目的训练，无论使用哪类训练数据，都可以达到非常好的AUC得分和节费率。成本敏感分类模型，由于本次只试验了csdt模型，且没有特别的调参和分折验证（和xgboost相比），因此并未能充分发挥其能力，效果并不是很理想。但是其模型理念更符合商业操作的实际情况，可以在等待模型训练更成熟的情况下使用。

贝叶斯最低风险剪枝，因为部分理念与成本敏感接近，因此在csdt中的表现并不是非常明显，但对于普通模型可以起到非常好的
提高节费率的效果。但是需要注意的是，该剪枝的理论背景是，如果树形决策的分支并不能提升节费率，则会被剪去，因此
通常会导致AUC或者说误判率的增加。试想一下，如果在判断一笔1美金的欺诈交易时，因为发卡机构设定的确认该笔交易是否
为欺诈的内部成本为2美金，所以并没有被判定为欺诈。但模型没有包含的潜在的损失是，持有该卡的用户收到了欺诈损失，丧失
对该卡的信任，转而投身其它发卡机构，而引发的用户离开。因此，没有任何模型是完美的，需要结合业务实际情况，分析欺诈检测的目的（或者多项目的的权重），才能选择最适合的模型。

# 5. 如何与本项目互动
欢迎提供修改或改善意见

# 6. 版权
BSD 3-clause

# 7. 作者
[Max Qiu](https://github.com/ft9738962)
